# About
I am Gabriela Juncosa, a **PhD candidate of Network Science** at Central European University. Currently writing up my dissertation, I expect to complete all work for my doctoral degree by August 2024. I am a **Digital Behaviour Researcher** interested in how Network and Data Science methods can aid our understanding of sociocultural phenomena in digital society. 

My doctoral dissertation explores the **dynamics of online behaviour**, focusing on how individuals navigate online social environments and enact their online behaviours. I'm interested in how our biases affect what we say and how they can make us hold back. Specifically, I'm looking at online contexts where people feel pressured to stay quiet and how these individual decisions interact to distort our understanding of what's popular online. To tackle this, I combine **empirical and experimental methods**.

I aim to continue leveraging the complementarity of empirical and experimental methods to deepen our understanding digital behaviour, while simultaneously producing research that is socially relevant, open and reproducible. I am committed to continuing the study of available **social media data**, as there is still much to be learned about the complex interactions that are facilitated, suppressed, or amplified. However, I acknowledge that observational social media data alone cannot adequately address relevant research questions regarding online behavior. Carefully designed **online social experiments** can effectively bridge this gap. As social media platforms increasingly limit access for such experiments, I'm eager to partner with fellow digital behavior researchers to enhance existing infrastructures and facilitate experimental research. 

# Research Projects

### Toxicity in online political deliberation: YouTube during the 2020 US presidential elections (*In preparation*)
Juncosa, G., Yasseri, T., Koltai, J., Iniguez, G.

Understanding how individuals respond to social influence is crucial for studying political collective behavior. While many opinion dynamics models focus on opinion feedback, they often overlook the potential for feedback to result in self-censorship. In this study, we investigate online political deliberation through the lens of the Spiral of Silence theory, which suggests that individuals may refrain from expressing minority opinions in public settings due to fear of isolation. Analyzing conversations in YouTube videos from six prominent US news outlets before and after the 2020 U.S. presidential elections, we aim to observe patterns of self-censorship and the influence of peer toxicity on users' behaviour. Using Hidden Markov models, we identified a latent state that aligns with the Spiral of Silence theory. This state is characterised by reduced user activity and higher likelihood of posting toxic content, indicating an environment where extreme behaviours thrive. These findings offer insights into the complexities of online political deliberation and emphasise the importance of considering self-censorship dynamics in understanding digital discourse.

### Harnessing collective wisdom for effective content moderation (*In preparation*)
Juncosa, G., Mohammadi, S., Samahita, M., Yasseri, T.

Social media platforms are under increasing scrutiny due to the rampant spread of misinformation. To combat this issue, platforms have adopted various strategies, including community-based content moderation, as an alternative to expert labeling and biased machine-learning approaches. While community-based moderation has been well-received, its effectiveness in tackling misinformation remains unclear. In this study, we evaluate Twitter's Community Notes feature, which prompts users to label tweets as misleading or not and provide contextual notes. Users can also rate the helpfulness of these labels and notes. Previous studies have shown that "Birdwatchers" tend to label and provide notes on counter-partisan content more frequently. However, a limitation of Twitter's Community Notes is the lack of collaborative note creation. We hypothesize that allowing users to collaborate in labeling and providing notes would result in more neutral outcomes. To test this hypothesis, we conduct an online experiment where human subjects collaborate on content moderation tasks. We aim to determine how group composition and the visibility of party affiliation affect the accuracy of fact-checking. Our findings reveal a nuanced interplay between group composition and tweet partisanship. While homogeneous-partisan teams exhibit higher effectiveness in evaluating Democratic tweets, contrary to expectations, heterogeneous teams excel in assessing Republican tweets. Furthermore, we show that teams work better at evaluating and annotating
misleading political content. These results underscore the importance of understanding group dynamics in combating political bias on social media platforms.

### Exploring the Impact of Online Collaborative Environments on the Willingness to Express Opinions: A Spiral of Silence Perspective (*In preparation*)
Juncosa, G., SÃ¡nchez, A., Koltai, J., Yasseri, T., Iniguez, G.

This research delves into the intricate relationship between human interaction and the processes of opinion formation and expression. While opinion dynamic models typically focus on interactions among individuals with differing viewpoints as drivers of opinion change, they often overlook how these interactions can influence behavior without necessarily altering core beliefs. Understanding how individuals respond to feedback and how their choices impact others' behavior is increasingly vital as more people globally engage with political content online. This study investigates how our inherent need for connection influences our decisions to share opinions on contentious topics in online discussions. To address this issue, we propose an online experiment to investigate whether collaborative online environments exacerbate individuals' fear of isolation, thereby lowering willingness to express their true opinions publicly. In our experiment, participants used an online interface to provide opinions on controversial topics, with the option to share or conceal their views with their connections. Participants were incentivised to form connections and faced penalties if others disconnected from them or rejected their attempts to connect. While our analysis is still underway, preliminary findings moderately support our hypothesis that individuals conceal their opinions in response to negative feedback. 

# Talks 



